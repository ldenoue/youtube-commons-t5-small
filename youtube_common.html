<html>
  <head>
    <meta charset="utf-8">
  </head>
<body>
  <script type="module">
import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers';

env.allowLocalModels = true;

// âœ… (Optional) set a default local path prefix for all models
// For example, if your model files are at http://localhost:8080/onnx_export/
env.localModelPath = "http://localhost:8000/";

const model = await pipeline(
  'text2text-generation',
  'onnx_export',  // local or hosted path
  { device: 'webgpu' } // uses WebGPU when available
);

const result = await model('this is a test without punctuation');
console.log(result[0].generated_text);


  </script>
</body>  
</html>
